{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abade38",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-03T15:33:16.595009Z",
     "end_time": "2023-04-03T15:33:16.603011Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_io\n",
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab271948",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-03T15:33:19.428614Z",
     "end_time": "2023-04-03T15:33:24.168042Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\jasmi\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/1356221609.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDropout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFlatten\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mConv2D\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMaxPooling2D\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequence\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpad_sequences\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\jasmi\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f391643",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-03T15:33:26.132667Z",
     "end_time": "2023-04-03T15:34:26.220143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "dir_path = 'Data/Archive_2'\n",
    "\n",
    "# Create a list to store the audio data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Set the maximum length of the MFCC feature matrices\n",
    "max_len = 862\n",
    "\n",
    "# Loop through the directories in the base directory\n",
    "for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "\n",
    "    # Loop through the audio files in each directory\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.wav'):\n",
    "            # Get the full path to the audio file\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Load the audio file\n",
    "            audio, sr = librosa.load(filepath)\n",
    "\n",
    "            # Extract the MFCC features\n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "\n",
    "            # Append the features and label to the data list\n",
    "            data.append(mfccs)\n",
    "            labels.append(os.path.basename(os.path.dirname(filepath)))\n",
    "\n",
    "# Pad the MFCC feature matrices to the same length\n",
    "data = pad_sequences(data, maxlen=max_len, padding='post', dtype='float32', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a660196a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-03T15:51:50.826159Z",
     "end_time": "2023-04-03T15:51:50.835161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-154.40219   -220.9058    -429.92896   ... -433.03455   -410.77133\n",
      "  -338.87708  ]\n",
      " [ 119.402985   120.652115    56.575882  ...   52.199768    74.98485\n",
      "   108.66513  ]\n",
      " [  14.304213    16.447674    43.330276  ...   39.19467     45.319626\n",
      "    28.103863 ]\n",
      " ...\n",
      " [   2.7608032    3.7864006    8.909393  ...    0.6091108    1.7350227\n",
      "     3.3905015]\n",
      " [   1.1594774    2.7529054    7.9375834 ...    2.6871736    2.440865\n",
      "     2.683006 ]\n",
      " [   2.2479491    3.152337     5.367258  ...    4.6718426    2.900693\n",
      "     2.89327  ]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T15:55:17.218062Z",
     "end_time": "2023-04-03T15:55:17.235067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef7549",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-03T11:46:41.500477Z",
     "end_time": "2023-04-03T11:46:41.521482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the number of audio files and their labels\n",
    "# print(f'Number of audio files: {len(data)}')\n",
    "# print(f'Labels: {set(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasmi\\AppData\\Local\\Temp/ipykernel_7552/264575378.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (40,862) into shape (40,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7552/264575378.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Convert the data and labels to NumPy arrays\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLabelEncoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_categorical\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not broadcast input array from shape (40,862) into shape (40,)"
     ]
    }
   ],
   "source": [
    "# Convert the data and labels to NumPy arrays\n",
    "X = np.array(data)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "y = to_categorical(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "mean = np.mean(X_train)\n",
    "std = np.std(X_train)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, verbose=1, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
